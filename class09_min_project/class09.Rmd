---
title: "class09"
author: "Anel A15426506"
date: "10/26/2021"
output:
  pdf_document: default
  html_document: default
---

#Data


```{r}
fna.data <- "WisconsinCancer.csv"
```

#completing the code
```{r}
wisc.df <- read.csv(fna.data, row.names = 1)
```

#examine data
```{r}
View(wisc.df)
```

# We can use -1 here to remove the first column
```{r}
wisc.data <- wisc.df[,-1]
```

#Diagnosis vector

```{r}
diagnosis <- as.factor(wisc.df[,1])
```

>Q1. How many observations are in this dataset?

```{r}
nrow(wisc.data)
```
There are 569 observations.


>Q2. How many of the observations have a malignant diagnosis?

```{r}
table(diagnosis)
```
 212 of the observatins have malignant diagnosis.

>Q3. How many variables/features in the data are suffixed with _mean?

```{r}
length(grep("mean", colnames(wisc.df)) )
```
10 features are suffixed with _mean.

# Check column means and standard deviations
```{r}
colMeans(wisc.data)
```


```{r}
apply(wisc.data,2,sd)
```

#PCA on wisc.data
```{r}
wisc.pr <- prcomp(wisc.data, scale. = TRUE)
```

#summary
```{r}
summary(wisc.pr)
```

>Q4. From your results, what proportion of the original variance is captured by the first principal components (PC1)?

44% of the variance is captured.

>Q5. How many principal components (PCs) are required to describe at least 70% of the original variance in the data?

3 PCs are required to describe at least 70% of the original variance.

>Q6. How many principal components (PCs) are required to describe at least 90% of the original variance in the data?

7 PCs are required to describe 90% of the original variance.

#plot
```{r}
biplot(wisc.pr)
```

>Q7. What stands out to you about this plot? Is it easy or difficult to understand? Why?

The plot is not useful because all of the information is mushed together into a blob making it hard to read.

# Scatter plot observations by components 1 and 2

```{r}
plot(wisc.pr$x)
```



```{r}
plot(wisc.pr$x[,1:2], col= factor(diagnosis), 
     xlab = "PC1", ylab = "PC2")
```

>Q8. Generate a similar plot for principal components 1 and 3. What do you notice about these plots?

```{r}
plot(wisc.pr$x[, c(1,3)],col = diagnosis, 
     xlab = "PC1", ylab = "PC3")
```
There isn't a big difference between the graphs besides the data. The data in PC1 VS. PC3 is less negative and more positive.

# Create a data.frame for ggplot
```{r}
df <- as.data.frame(wisc.pr$x)
df$diagnosis <- diagnosis
```


# Load the ggplot2 package
```{r}
library(ggplot2)
```


# Make a scatter plot colored by diagnosis
```{r}
ggplot(df) + 
  aes(PC1, PC2, col=diagnosis) + 
  geom_point()
```

# Calculate variance of each component
```{r}
pr.var <- wisc.pr$sdev^2
head(pr.var)
```

# Variance explained by each principal component: pve
```{r}
pve <- pr.var / sum((pr.var))
```


# Plot variance explained for each principal component
```{r}
plot(pve, xlab = "Principal Component", 
     ylab = "Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")
```

# Alternative scree plot of the same data, note data driven y-axis
```{r}
barplot(pve, ylab = "Precent of Variance Explained",
     names.arg=paste0("PC",1:length(pve)), las=2, axes = FALSE)
axis(2, at=pve, labels=round(pve,2)*100 )
```

>Q9. For the first principal component, what is the component of the loading vector (i.e. wisc.pr$rotation[,1]) for the feature concave.points_mean?

```{r}
wisc.pr$rotation["concave.points_mean",1]
```


>Q10. What is the minimum number of principal components required to explain 80% of the variance of the data?

The minimum number is 8 principal components.

```{r}
summary(wisc.pr)
```

# Scale the wisc.data data using the "scale()" function
```{r}
data.scaled <- scale(wisc.data)
```

```{r}
data.dist <- dist(data.scaled)
```

```{r}
wisc.hclust <- hclust(data.dist)
```


```{r}
plot(wisc.hclust)
```

>Q11. Using the plot() and abline() functions, what is the height at which the clustering model has 4 clusters?

The height is 21.

```{r}
plot(wisc.hclust)
abline(h=19, col="red", lty=2)
```


```{r}
wisc.hclust.clusters <- cutree(wisc.hclust, k=4)
```
>Q12. Can you find a better cluster vs diagnoses match by cutting into a different number of clusters between 2 and 10?

The better on is a cluster of 2.

>Q13. Which method gives your favorite results for the same data.dist dataset? Explain your reasoning

Ward.D2 gives my favorite dataset because there's less varaince when looking at the data.

cut the tree to k=2

```{r}
wisc.pc.hclust <- hclust(dist(wisc.pr$x[,1:3]),
                         method="ward.D2")
```

```{r}
wisc.pc.hclust <- hclust(dist(wisc.pr$x[,1:3]),
                         method="single")
```


```{r}
summary(wisc.pr)
```


```{r}
grps <- cutree(wisc.pc.hclust, k=2)
table(grps)
```
cross table compared of diagnosis and my cluster groups

```{r}
table(grps, diagnosis)
```

```{r}
plot(wisc.pr$x[,1:2], col=grps)
```

```{r}
plot(wisc.pr$x[,1:2], col=diagnosis)
```

```{r}
g <- as.factor(grps)
levels(g)
```


```{r}
g <- relevel(g,2)
levels(g)
```

# Plot using our re-ordered factor 
```{r}
plot(wisc.pr$x[,1:2], col=g)
```


## Use the distance along the first 7 PCs for clustering i.e. wisc.pr$x[, 1:7]
```{r}
wisc.pr.hclust <- hclust(dist(wisc.pr$x[, 1:7]), method="ward.D2")
```

```{r}
wisc.pr.hclust.clusters <- cutree(wisc.pr.hclust, k=2)
```

>Q15. How well does the newly created model with four clusters separate out the two diagnoses?

It did well at sperating the two diagnoses

# Compare to actual diagnoses
```{r}
table(wisc.pr.hclust.clusters, diagnosis)
```



```{r}
table(wisc.hclust.clusters, diagnosis)
```

>Q17. Which of your analysis procedures resulted in a clustering model with the best specificity? How about sensitivity?

6. Sensitivity/Specificity
Sensitivity refers to a test’s ability to correctly detect ill patients who do have the condition. In our example here the sensitivity is the total number of samples in the cluster identified as predominantly malignant (cancerous) divided by the total number of known malignant samples. In other words: TP/(TP+FN).

```{r}
179/(179+33)
```

Specificity relates to a test’s ability to correctly reject healthy patients without a condition. In our example specificity is the proportion of benign (not cancerous) samples in the cluster identified as predominantly benign that are known to be benign. In other words: TN/(TN+FN).

```{r}
333/(333+24)
```


#url <- "new_samples.csv"

```{r}
url <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url)
npc <- predict(wisc.pr, newdata=new)
npc
```

```{r}
plot(wisc.pr$x[,1:2], col=g)
points(npc[,1], npc[,2], col="blue", pch=16, cex=3)
text(npc[,1], npc[,2], c(1,2), col="white")
```

>Q18. Which of these new patients should we prioritize for follow up based on your results?

The patient that should be prioritized is number 2.

